{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Flowers_classi.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwGUKZYEmt5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CNN_Flowers_classi.ipynb"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4TUwyllWOv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeEhGkKyrNN0",
        "colab_type": "text"
      },
      "source": [
        "# Image data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_W5318orTTg",
        "colab_type": "text"
      },
      "source": [
        "ImageDataGenerator (Data Augumentation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j07TniXPbcPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    rescale=1/255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2\n",
        ")\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1/255,\n",
        ")"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoLvYwMlbi6q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e765674d-41af-4c2a-97b1-239b58f1d6e9"
      },
      "source": [
        "batch_size = 128\n",
        "\n",
        "# Notice the tiny target size, just 32x32!\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/My Drive/CNN/flower_Image_data/train_flower',\n",
        "    target_size=(32, 32),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/My Drive/CNN/flower_Image_data/test_flower',\n",
        "    target_size=(32, 32),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 330 images belonging to 2 classes.\n",
            "Found 66 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_skDJOqrabU",
        "colab_type": "text"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGcWx9P4bnq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = Sequential()\n",
        "# #model.add(prior)\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(256, activation='relu', name='Dense_Intermediate'))\n",
        "# model.add(Dropout(0.1, name='Dropout_Regularization'))\n",
        "# model.add(Dense(12, activation='sigmoid', name='Output'))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xdgu3FtdSic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#opt = SGD(lr=0.001, momentum=0.9)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# model.compile(\n",
        "#     optimizer=RMSprop(),\n",
        "#     loss='categorical_crossentropy',\n",
        "#     metrics=['accuracy']\n",
        "# )"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksJFfYNUmZvo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "outputId": "3adc6eef-cd85-4c76-b609-50966ecf1da2"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 549,538\n",
            "Trainable params: 549,538\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhtS30IYl0qG",
        "colab_type": "text"
      },
      "source": [
        "**Fit the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Oyg2dusex0j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cbe24b29-489b-45a6-e263-a3e93e250135"
      },
      "source": [
        "# fit the model\n",
        "r = model.fit_generator(train_generator,\n",
        "                        validation_data=validation_generator,\n",
        "                        epochs=50,\n",
        "                        steps_per_epoch=len(train_generator),\n",
        "                        validation_steps=len(validation_generator),\n",
        "                        #callbacks=[\n",
        "        #EarlyStopping(patience=3, restore_best_weights=True),\n",
        "        #ReduceLROnPlateau(patience=2)]\n",
        "                        )"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 3.9459 - accuracy: 0.4667 - val_loss: 0.8083 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.9888 - accuracy: 0.5000 - val_loss: 0.6868 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.7115 - accuracy: 0.5030 - val_loss: 0.6873 - val_accuracy: 0.6061\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.6895 - accuracy: 0.5394 - val_loss: 0.6950 - val_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.6977 - accuracy: 0.5061 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.6945 - accuracy: 0.4970 - val_loss: 0.6905 - val_accuracy: 0.5303\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.6856 - accuracy: 0.5939 - val_loss: 0.6859 - val_accuracy: 0.7879\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.6810 - accuracy: 0.6485 - val_loss: 0.6793 - val_accuracy: 0.6818\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6721 - accuracy: 0.6455 - val_loss: 0.6531 - val_accuracy: 0.7121\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.6497 - accuracy: 0.6424 - val_loss: 0.5707 - val_accuracy: 0.8333\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.6042 - accuracy: 0.7242 - val_loss: 0.4988 - val_accuracy: 0.8030\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.5219 - accuracy: 0.7697 - val_loss: 0.4550 - val_accuracy: 0.8030\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.5758 - accuracy: 0.6909 - val_loss: 0.4505 - val_accuracy: 0.7727\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.5690 - accuracy: 0.7455 - val_loss: 0.4695 - val_accuracy: 0.7727\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.5038 - accuracy: 0.7667 - val_loss: 0.4579 - val_accuracy: 0.8030\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.4960 - accuracy: 0.7545 - val_loss: 0.4556 - val_accuracy: 0.8333\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.4847 - accuracy: 0.7848 - val_loss: 0.4707 - val_accuracy: 0.8030\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.4933 - accuracy: 0.7545 - val_loss: 0.4249 - val_accuracy: 0.8333\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.4720 - accuracy: 0.7909 - val_loss: 0.4240 - val_accuracy: 0.8030\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.4854 - accuracy: 0.7576 - val_loss: 0.3868 - val_accuracy: 0.8030\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.4668 - accuracy: 0.7848 - val_loss: 0.4336 - val_accuracy: 0.7576\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.4649 - accuracy: 0.7788 - val_loss: 0.4321 - val_accuracy: 0.8485\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.4663 - accuracy: 0.8000 - val_loss: 0.5059 - val_accuracy: 0.7424\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.5105 - accuracy: 0.7333 - val_loss: 0.4255 - val_accuracy: 0.8788\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.4281 - accuracy: 0.7818 - val_loss: 0.4521 - val_accuracy: 0.8030\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.4487 - accuracy: 0.7909 - val_loss: 0.4059 - val_accuracy: 0.8333\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.4389 - accuracy: 0.7970 - val_loss: 0.3966 - val_accuracy: 0.8182\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.4558 - accuracy: 0.7879 - val_loss: 0.4296 - val_accuracy: 0.8182\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.4430 - accuracy: 0.7788 - val_loss: 0.3419 - val_accuracy: 0.8485\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.4012 - accuracy: 0.8182 - val_loss: 0.4189 - val_accuracy: 0.7727\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.4324 - accuracy: 0.8091 - val_loss: 0.4109 - val_accuracy: 0.8333\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.4233 - accuracy: 0.8152 - val_loss: 0.3970 - val_accuracy: 0.8182\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.4049 - accuracy: 0.8121 - val_loss: 0.3597 - val_accuracy: 0.8485\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.3871 - accuracy: 0.8152 - val_loss: 0.3662 - val_accuracy: 0.8333\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.4178 - accuracy: 0.8061 - val_loss: 0.3943 - val_accuracy: 0.8636\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.3863 - accuracy: 0.8364 - val_loss: 0.3820 - val_accuracy: 0.8485\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.3541 - accuracy: 0.8394 - val_loss: 0.3523 - val_accuracy: 0.8636\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.3706 - accuracy: 0.8242 - val_loss: 0.3480 - val_accuracy: 0.8485\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.3808 - accuracy: 0.8212 - val_loss: 0.3259 - val_accuracy: 0.8485\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.3599 - accuracy: 0.8394 - val_loss: 0.4634 - val_accuracy: 0.7879\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.3957 - accuracy: 0.8182 - val_loss: 0.3258 - val_accuracy: 0.8636\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.3589 - accuracy: 0.8273 - val_loss: 0.2988 - val_accuracy: 0.8333\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.3557 - accuracy: 0.8455 - val_loss: 0.3184 - val_accuracy: 0.8182\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.3157 - accuracy: 0.8455 - val_loss: 0.2852 - val_accuracy: 0.8939\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.3468 - accuracy: 0.8576 - val_loss: 0.2305 - val_accuracy: 0.8485\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.3038 - accuracy: 0.8667 - val_loss: 0.4351 - val_accuracy: 0.7879\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.3340 - accuracy: 0.8576 - val_loss: 0.2845 - val_accuracy: 0.9091\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.4245 - accuracy: 0.8364 - val_loss: 0.4167 - val_accuracy: 0.8333\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.3696 - accuracy: 0.8545 - val_loss: 0.2686 - val_accuracy: 0.9545\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.3431 - accuracy: 0.8576 - val_loss: 0.3879 - val_accuracy: 0.8333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLXOp896pwLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # save model\n",
        "# model.save('my_flower_classi_model')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjfU1Bstlrp9",
        "colab_type": "text"
      },
      "source": [
        "# Prediction\n",
        "\n",
        "Class [0] means it is a 'Lotus Image'\n",
        "\n",
        "Class [1] means it is a 'Rose Image'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFSkuwR0qhKQ",
        "colab_type": "text"
      },
      "source": [
        "Load Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGkPcenMgf3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "image = image.load_img('/content/drive/My Drive/CNN/flower_Image_data/validate_flower_image/image_01164.jpg', target_size=(32, 32))\n",
        "input_arr = keras.preprocessing.image.img_to_array(image)\n",
        "#x = np.expand_dims(input_arr, axis=0)   ## Convert single image to a batch.\n",
        "input_arr = np.array([input_arr])        ## Convert single image to a batch.\n",
        "#predictions = model.predict(input_arr)\n",
        "\n",
        " "
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKV3tLjhqZmF",
        "colab_type": "text"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QYqci23qLjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load model\n",
        "#model = load_model('my_flower_classi_model')\n",
        "predictions_classes = model.predict_classes(input_arr)\n",
        "\n",
        "def predict_img():\n",
        "  if predictions_classes ==0:\n",
        "    print(\"Class {} means it is a 'Lotus Image'\".format(predictions_classes))\n",
        "  if predictions_classes ==1:\n",
        "    print(\"Class {} means it is a 'Rose Image'\".format(predictions_classes)) "
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtTOTlrUilw0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "c6acd5bb-8a43-4ff8-eac5-e28d36a03240"
      },
      "source": [
        "image"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F502C0DBBA8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJaBEXjshgDs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "517a93c7-66e4-404c-929e-b17f89056389"
      },
      "source": [
        "predict_img()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class [1] means it is a 'Rose Image'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5VYvF4eJBxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}