{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Clothes_Classi_Augu_Optimizers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtw90CR6BnnY",
        "colab_type": "text"
      },
      "source": [
        "# Yogendra Verma\n",
        "Assignment-4(V1)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF5VL2DiNDAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dropout\n",
        "from keras.callbacks import EarlyStopping ,ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGNRbm9agq65",
        "colab_type": "text"
      },
      "source": [
        "**Define CNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoF3yjJkV-Hk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(64, 64, 3)))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  #model.add(Dropout(0.2))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  #model.add(Dropout(0.2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "  #model.add(Dropout(0.4))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\t# compile model\n",
        "  #opt = SGD(lr=0.001, momentum=0.9)\n",
        "  #opt = keras.optimizers.Adadelta()\n",
        "  #opt = keras.optimizers.RMSprop(lr=0.001)\n",
        "  #opt = keras.optimizers.Nadam(lr=0.001)\n",
        "  #opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "  #opt = keras.optimizers.SGD(momentum=0.01, nesterov=True)\n",
        "  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEY4IgES0MpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(filename + '_plot.png')\n",
        "\tpyplot.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8POh05io0ig9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "8329dcf7-dc3a-428e-bc7f-c2d12d08e278"
      },
      "source": [
        "\n",
        "model = define_model()\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_33 (Conv2D)           (None, 64, 64, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_34 (MaxPooling (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_17 (Flatten)         (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 128)               2097280   \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,116,801\n",
            "Trainable params: 2,116,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asan_1Wwghfc",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Clothes Image Dataset with Data Augumentation Technique**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anZTsaW8WaR7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9c212ae9-2af5-42f6-ca04-e7e8eccff173"
      },
      "source": [
        "# call define model function\n",
        "model = define_model()\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "# prepare iterators\n",
        "train_it = datagen.flow_from_directory('/content/drive/My Drive/CNN/fk_clothes_data/augu_data_train',\n",
        "class_mode='binary', batch_size=70, target_size=(64, 64))\n",
        "test_it = datagen.flow_from_directory('/content/drive/My Drive/CNN/fk_clothes_data/test_clothes',\n",
        "class_mode='binary', batch_size=70, target_size=(64, 64))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1262 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L4T3zyqDnjc",
        "colab_type": "text"
      },
      "source": [
        "**Implement EarlyStopping & Checkpoint**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsuCBhXmEOWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint('/content/drive/My Drive/CNN/fk_clothes_data/model_checkpoint_SGD_nesterov.h5',\n",
        "                             monitor='val_loss', \n",
        "                             verbose=1, \n",
        "                             save_best_only=True, \n",
        "                             mode='min')\n",
        "callbacks =[checkpoint] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1BI1ti6eUD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "earlystop = EarlyStopping(monitor='val_loss', \n",
        "                          min_delta=0, \n",
        "                          patience=3, \n",
        "                          verbose=1, \n",
        "                          restore_best_weights=True)\n",
        "\n",
        "callbacks = [earlystop,checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi4sUfQVQNkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
        "#                                             patience=3, \n",
        "#                                             verbose=1, \n",
        "#                                             factor=0.2, \n",
        "#                                             min_delta=0.0001)\n",
        "# callbacks = [learning_rate_reduction]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BBOItjWsPdM",
        "colab_type": "text"
      },
      "source": [
        "**Train the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eSGRJlrsJZy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4f5ce420-0eff-4bad-85c3-93e9ebed5bf3"
      },
      "source": [
        "# fit model\n",
        "history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
        "validation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=1,callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "19/19 [==============================] - 4s 199ms/step - loss: 0.7988 - accuracy: 0.5357 - val_loss: 0.6598 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.65979, saving model to /content/drive/My Drive/CNN/fk_clothes_data/model_checkpoint_SGD_nesterov.h5\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 4s 196ms/step - loss: 0.6692 - accuracy: 0.5697 - val_loss: 0.8520 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.65979\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 4s 197ms/step - loss: 0.6784 - accuracy: 0.5983 - val_loss: 0.6368 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.65979 to 0.63682, saving model to /content/drive/My Drive/CNN/fk_clothes_data/model_checkpoint_SGD_nesterov.h5\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 4s 195ms/step - loss: 0.6756 - accuracy: 0.6038 - val_loss: 0.6376 - val_accuracy: 0.6500\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.63682\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 4s 198ms/step - loss: 0.6466 - accuracy: 0.6315 - val_loss: 0.6073 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.63682 to 0.60726, saving model to /content/drive/My Drive/CNN/fk_clothes_data/model_checkpoint_SGD_nesterov.h5\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 4s 194ms/step - loss: 0.6512 - accuracy: 0.6680 - val_loss: 0.5995 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.60726 to 0.59952, saving model to /content/drive/My Drive/CNN/fk_clothes_data/model_checkpoint_SGD_nesterov.h5\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 4s 194ms/step - loss: 0.6542 - accuracy: 0.6886 - val_loss: 0.5878 - val_accuracy: 0.8250\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.59952 to 0.58782, saving model to /content/drive/My Drive/CNN/fk_clothes_data/model_checkpoint_SGD_nesterov.h5\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - 4s 191ms/step - loss: 0.5991 - accuracy: 0.6712 - val_loss: 0.5779 - val_accuracy: 0.6500\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.58782 to 0.57788, saving model to /content/drive/My Drive/CNN/fk_clothes_data/model_checkpoint_SGD_nesterov.h5\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - 4s 191ms/step - loss: 0.5854 - accuracy: 0.6862 - val_loss: 0.5799 - val_accuracy: 0.6000\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.57788\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - 4s 194ms/step - loss: 0.5840 - accuracy: 0.7314 - val_loss: 0.5251 - val_accuracy: 0.9250\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.57788 to 0.52514, saving model to /content/drive/My Drive/CNN/fk_clothes_data/model_checkpoint_SGD_nesterov.h5\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - 4s 195ms/step - loss: 0.5456 - accuracy: 0.7377 - val_loss: 0.5801 - val_accuracy: 0.5750\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.52514\n",
            "Epoch 12/20\n",
            "19/19 [==============================] - 4s 201ms/step - loss: 0.5702 - accuracy: 0.7607 - val_loss: 0.4924 - val_accuracy: 0.9250\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.52514 to 0.49237, saving model to /content/drive/My Drive/CNN/fk_clothes_data/model_checkpoint_SGD_nesterov.h5\n",
            "Epoch 13/20\n",
            "19/19 [==============================] - 4s 203ms/step - loss: 0.5002 - accuracy: 0.7655 - val_loss: 0.4697 - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.49237 to 0.46966, saving model to /content/drive/My Drive/CNN/fk_clothes_data/model_checkpoint_SGD_nesterov.h5\n",
            "Epoch 14/20\n",
            "19/19 [==============================] - 4s 196ms/step - loss: 0.4712 - accuracy: 0.8074 - val_loss: 0.5309 - val_accuracy: 0.6500\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.46966\n",
            "Epoch 15/20\n",
            "19/19 [==============================] - 4s 203ms/step - loss: 0.4706 - accuracy: 0.7916 - val_loss: 0.4227 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.46966 to 0.42269, saving model to /content/drive/My Drive/CNN/fk_clothes_data/model_checkpoint_SGD_nesterov.h5\n",
            "Epoch 16/20\n",
            "19/19 [==============================] - 4s 193ms/step - loss: 0.5507 - accuracy: 0.7932 - val_loss: 0.4410 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.42269\n",
            "Epoch 17/20\n",
            "19/19 [==============================] - 4s 195ms/step - loss: 0.4892 - accuracy: 0.8177 - val_loss: 0.4161 - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.42269 to 0.41609, saving model to /content/drive/My Drive/CNN/fk_clothes_data/model_checkpoint_SGD_nesterov.h5\n",
            "Epoch 18/20\n",
            "19/19 [==============================] - 4s 195ms/step - loss: 0.3968 - accuracy: 0.8582 - val_loss: 0.3706 - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.41609 to 0.37058, saving model to /content/drive/My Drive/CNN/fk_clothes_data/model_checkpoint_SGD_nesterov.h5\n",
            "Epoch 19/20\n",
            "19/19 [==============================] - 4s 194ms/step - loss: 0.3935 - accuracy: 0.8312 - val_loss: 0.4384 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.37058\n",
            "Epoch 20/20\n",
            "19/19 [==============================] - 4s 213ms/step - loss: 0.3451 - accuracy: 0.8550 - val_loss: 0.3640 - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.37058 to 0.36401, saving model to /content/drive/My Drive/CNN/fk_clothes_data/model_checkpoint_SGD_nesterov.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E2-ORWVQsh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.save_weights('/content/drive/My Drive/CNN/fk_clothes_data/model_ReduceLROnPlateau_SGD.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J0XErWCWpp9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1333a958-0d6f-4932-e9d4-7abece5bd414"
      },
      "source": [
        "# evaluate model\n",
        "_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))\n",
        "# learning curves\n",
        "summarize_diagnostics(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> 90.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ON1VfKxgGiK",
        "colab_type": "text"
      },
      "source": [
        "**Load Image for Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrtWC4l2W0GJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "image = image.load_img('/content/drive/My Drive/CNN/fk_clothes_data/validate_clothes/tr4.jpeg', target_size=(64, 64))\n",
        "input_arr = keras.preprocessing.image.img_to_array(image)\n",
        "#x = np.expand_dims(input_arr, axis=0)   ## Convert single image to a batch.\n",
        "input_arr = np.array([input_arr])        ## Convert single image to a batch.\n",
        "#predictions = model.predict(input_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-olTT5k-gW9K",
        "colab_type": "text"
      },
      "source": [
        "**Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru-KQUWQX_rA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "# load model\n",
        "#model = load_model('my_flower_classi_model')\n",
        "#predictions_classes = model.predict_classes(input_arr)\n",
        "\n",
        "predictions_classes = model.predict_classes(input_arr)\n",
        "\n",
        "def predict_img():\n",
        "  if predictions_classes ==0:\n",
        "    print(\"Class {} means it is a 'Jeans Image'\".format(predictions_classes))\n",
        "  if predictions_classes ==1:\n",
        "    print(\"Class {} means it is a 'Trouser Image'\".format(predictions_classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mysYGPRYYNW2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "7fe171ad-fefc-4195-b5d2-6741e1cde383"
      },
      "source": [
        "image"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7FED7F371FD0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsGI9J0tYQcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "097833cd-5d4c-4434-d58f-3c46f3be883b"
      },
      "source": [
        "predict_img()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class [[1]] means it is a 'Trouser Image'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTcSAF3lfqMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
